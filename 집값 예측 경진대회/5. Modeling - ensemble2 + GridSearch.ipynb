{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KernelRidge, GradientBoost, XGBoost, LGBM\n",
    "- 참고 : https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard#Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#한글폰트 설정\n",
    "import matplotlib.font_manager as fm\n",
    "path = 'C:\\\\Users\\\\myksh\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\Fonts\\\\NanumGothic.ttf'\n",
    "# path = 'C:\\\\Users\\\\myksh\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\Fonts\\\\NanumSquare.ttf'\n",
    "font_name = fm.FontProperties(fname=path).get_name()\n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "#마이너스가 깨질 것을 방지\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#연대 정리해주는 함수\n",
    "def tail_year(x):\n",
    "    if 0<=x<10:\n",
    "        return '00'\n",
    "    elif 10<=x<20:\n",
    "        return '10'\n",
    "    elif 20<=x<30:\n",
    "        return '20'\n",
    "    elif 30<=x<40:\n",
    "        return '30'\n",
    "    elif 40<=x<50:\n",
    "        return '40'\n",
    "    elif 50<=x<60:\n",
    "        return '50'\n",
    "    elif 60<=x<70:\n",
    "        return '60'\n",
    "    elif 70<=x<80:\n",
    "        return '70'\n",
    "    elif 80<=x<90:\n",
    "        return '80'\n",
    "    elif 90<=x<100:\n",
    "        return '90'\n",
    "def year_processing(x):\n",
    "    xx = str(x)\n",
    "    if xx[:2] == '18':\n",
    "        return '18' + tail_year(int(xx[2:]))\n",
    "    elif xx[:2] == '19':\n",
    "        return '19' + tail_year(int(xx[2:]))\n",
    "    elif xx[:2] == '20':\n",
    "        return '20' + tail_year(int(xx[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#연대별로 변경\n",
    "train['Year Built'] = train['Year Built'].apply(lambda x:year_processing(x))\n",
    "train['Year Built'] = train['Year Built'].astype(int)\n",
    "\n",
    "test['Year Built'] = test['Year Built'].apply(lambda x:year_processing(x))\n",
    "test['Year Built'] = test['Year Built'].astype(int)\n",
    "\n",
    "#연대별로 정리\n",
    "train['Year Remod/Add'] = train['Year Remod/Add'].apply(lambda x:year_processing(x))\n",
    "train['Year Remod/Add'] = train['Year Remod/Add'].astype(int)\n",
    "\n",
    "test['Year Remod/Add'] = test['Year Remod/Add'].apply(lambda x:year_processing(x))\n",
    "test['Year Remod/Add'] = test['Year Remod/Add'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#차고 자리 개수와 차고 면적은 의미가 비슷하므로 자리 개수를 drop\n",
    "train = train.drop('Garage Cars', axis=1)\n",
    "test = test.drop('Garage Cars', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2207년 데이터 삭제\n",
    "train = train.drop(train[train['Garage Yr Blt']>=2022].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cols = ['Exter Qual','Kitchen Qual','Bsmt Qual']\n",
    "for i in cols:\n",
    "    train[i] = le.fit_transform(train[i])\n",
    "    test[i] = le.fit_transform(test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대회 규칙의 평가 산식 함수를 그대로 사용\n",
    "def NMAE(true, pred):\n",
    "    mae = np.mean(np.abs(true-pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('target', axis=1)\n",
    "y = np.log1p(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1079, 12), (270, 12))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, LassoCV, ElasticNetCV, RidgeCV, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def gridSearchCV(models,params):\n",
    "    kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_models=[]\n",
    "    for i in tqdm(range(0,len(models))):\n",
    "        model_grid = GridSearchCV(models[i], params[i],n_jobs = -1, verbose=1, cv=kfolds)\n",
    "        model_grid.fit(X_train, y_train)\n",
    "        best_models.append(model_grid.best_estimator_)\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, l1_ratio=e_l1ratio, random_state=42, cv=kfolds))\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lr = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "#                                    max_depth=4, max_features='sqrt',\n",
    "#                                    min_samples_leaf=15, min_samples_split=10, \n",
    "#                                    loss='huber', random_state =5)\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e659a1119ca54040a118f7614d23fcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 330 candidates, totalling 1650 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 44.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed: 59.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbr_params = {'loss' : ['huber', 'quantile'],\n",
    "             'learning_rate':[0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15],\n",
    "             'n_estimators':[1000, 2000, 3000],\n",
    "              'max_depth':[5,7,10,15,20],\n",
    "              'max_features':['sqrt'],\n",
    "              'min_samples_leaf':[15],\n",
    "              'min_samples_split':[10]}\n",
    "xgb_params = {'n_estimators' : [1000, 2000],\n",
    "              \"early_stopping_rounds\" : [1, 2],\n",
    "              'learning_rate':[0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15]}\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "grid = gridSearchCV([gbr, model_xgb], [gbr_params, xgb_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = grid[0]\n",
    "model_xgb = grid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=1,\n",
       "             gamma=0, gpu_id=-1, importance_type='gain',\n",
       "             interaction_constraints='', learning_rate=0.11, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=1000, n_jobs=8,\n",
       "             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso score: 0.1453 (0.0266)\n",
      "ridge score: 0.1455 (0.0272)\n",
      "ElasticNet score: 0.1454 (0.0266)\n",
      "Kernel Ridge score: 0.1436 (0.0200)\n",
      "Gradient Boosting score: 0.1461 (0.0265)\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "LGBM score: 0.1425 (0.0251)\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"Lasso score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(ridge)\n",
    "print(\"ridge score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "# score = rmsle_cv(model_xgb)\n",
    "# print(\"Xgboost score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=0.6, coef0=2.5, degree=2, kernel='polynomial')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "              feature_fraction=0.2319, feature_fraction_seed=9,\n",
       "              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n",
       "              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n",
       "              objective='regression')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "ENet.fit(X_train, y_train)\n",
    "KRR.fit(X_train, y_train)\n",
    "GBoost.fit(X_train, y_train)\n",
    "# model_xgb.fit(X_train, y_train)\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pred = ridge.predict(X_test)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "enet_pred = ENet.predict(X_test)\n",
    "krr_pred = KRR.predict(X_test)\n",
    "gb_pred = GBoost.predict(X_test)\n",
    "xgb_pred = model_xgb.predict(X_test)\n",
    "lgb_pred = model_lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pred = ((lasso_pred*0.4) + (enet_pred*0.3) + (krr_pred*0.3))*0.6 + ((ridge_pred*0.5)+(lgb_pred*0.5))*0.4\n",
    "final_pred = ((ridge_pred*0.5)+(lgb_pred*0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00837709738855337"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMAE(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00821083425712647"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMAE(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_pred = lasso.predict(test)\n",
    "enet_pred = ENet.predict(test)\n",
    "krr_pred = KRR.predict(test)\n",
    "gb_pred = GBoost.predict(test)\n",
    "xgb_pred = model_xgb.predict(test)\n",
    "lgb_pred = model_lgb.predict(test)\n",
    "\n",
    "final_pred = ((lasso_pred*0.4) + (enet_pred*0.3) + (krr_pred*0.3))*0.6 + ((gb_pred*0.5)+(lgb_pred*0.5))*0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>346439.374835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>124849.475923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>170880.716007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>243356.425448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>129385.819667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1346</td>\n",
       "      <td>330427.811054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>123317.596863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1348</td>\n",
       "      <td>75590.443907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1349</td>\n",
       "      <td>180893.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1350</td>\n",
       "      <td>134824.927799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         target\n",
       "0        1  346439.374835\n",
       "1        2  124849.475923\n",
       "2        3  170880.716007\n",
       "3        4  243356.425448\n",
       "4        5  129385.819667\n",
       "...    ...            ...\n",
       "1345  1346  330427.811054\n",
       "1346  1347  123317.596863\n",
       "1347  1348   75590.443907\n",
       "1348  1349  180893.333334\n",
       "1349  1350  134824.927799\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "sub['target'] = np.expm1(final_pred1)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub.to_csv('./submission_data/ensemble_submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, l1_ratio=e_l1ratio, random_state=42, cv=kfolds))\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df47458337ff45988c982c37c110f7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 28.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rf_params = {'n_estimators':[10, 20, 30, 1000, 2000, 3000],\n",
    "             \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "             \"bootstrap\": [True, False],\n",
    "             \"min_samples_split\" : [2,4,8],\n",
    "              'max_depth':[5,7,10,15,20]}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_grid = gridSearchCV([rf], [rf_params])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_split=4,\n",
       "                      n_estimators=2000)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('rf',\n",
       "                             RandomForestRegressor(max_depth=20,\n",
       "                                                   max_features='sqrt',\n",
       "                                                   min_samples_split=4,\n",
       "                                                   n_estimators=2000)),\n",
       "                            ('krr',\n",
       "                             KernelRidge(alpha=0.6, coef0=2.5, degree=2,\n",
       "                                         kernel='polynomial')),\n",
       "                            ('gbr',\n",
       "                             GradientBoostingRegressor(learning_rate=0.05,\n",
       "                                                       loss='huber',\n",
       "                                                       max_depth=10,\n",
       "                                                       max_features='sqrt',\n",
       "                                                       min_samples_leaf=15,\n",
       "                                                       min_samples_split=10,\n",
       "                                                       n_estimators=3000,\n",
       "                                                       random_state=5)),\n",
       "                            ('lgbm',\n",
       "                             LGBMRegressor(learning_rate=0.05, max_bin=55,\n",
       "                                           min_data_in_leaf=6,\n",
       "                                           min_sum_hessian_in_leaf=11,\n",
       "                                           n_estimators=720, num_leaves=5,\n",
       "                                           objective='regression'))])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "models = [\n",
    "    ('rf', RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_split=4, n_estimators=2000)),\n",
    "    ('krr', KernelRidge(alpha=0.6, coef0=2.5, degree=2, kernel='polynomial')),\n",
    "    ('gbr', GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                       max_depth=10, max_features='sqrt',\n",
    "                                       min_samples_leaf=15, min_samples_split=10, \n",
    "                                       loss='huber', random_state =5)),\n",
    "    ('lgbm', lgb.LGBMRegressor(learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n",
    "                              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=5,\n",
    "                              objective='regression'))\n",
    "]\n",
    "\n",
    "voting_rg = VotingRegressor(estimators=models)\n",
    "voting_rg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007903898812490536"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMAE(y_test, voting_rg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>345558.817782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>123504.614308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>174845.413270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>243110.508826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>130882.924565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>1346</td>\n",
       "      <td>329308.652637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>125758.743120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1348</td>\n",
       "      <td>77250.396398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1349</td>\n",
       "      <td>180757.513253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1350</td>\n",
       "      <td>137864.619894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         target\n",
       "0        1  345558.817782\n",
       "1        2  123504.614308\n",
       "2        3  174845.413270\n",
       "3        4  243110.508826\n",
       "4        5  130882.924565\n",
       "...    ...            ...\n",
       "1345  1346  329308.652637\n",
       "1346  1347  125758.743120\n",
       "1347  1348   77250.396398\n",
       "1348  1349  180757.513253\n",
       "1349  1350  137864.619894\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = voting_rg.predict(test)\n",
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "sub['target'] = np.expm1(pred)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf(grid), krr, gbr, lgbm voting\n",
    "sub.to_csv('./submission_data/voting_submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostRegressor\n",
    "# adaboost = AdaBoostRegressor(base_estimator=voting_rg)\n",
    "# adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMAE(y_test, adaboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
